{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af109d31",
   "metadata": {
    "id": "af109d31",
    "outputId": "0c3a16fc-517c-4630-f03d-e29b74bf8cdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Using cached gensim-4.3.2-cp310-cp310-macosx_11_0_arm64.whl (24.0 MB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/shreyavinaynayak/miniconda3/lib/python3.10/site-packages (from gensim) (1.25.2)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Using cached smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /Users/shreyavinaynayak/miniconda3/lib/python3.10/site-packages (from gensim) (1.11.2)\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.3.2 smart-open-6.4.0\n"
     ]
    }
   ],
   "source": [
    "! pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95799724",
   "metadata": {
    "id": "95799724",
    "outputId": "6e07079c-6dd8-4beb-f4cb-c0b66f5e8f2f",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.0.1-cp310-none-macosx_11_0_arm64.whl (55.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.15.2-cp310-cp310-macosx_11_0_arm64.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio\n",
      "  Downloading torchaudio-2.0.2-cp310-cp310-macosx_11_0_arm64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.12.4-py3-none-any.whl (11 kB)\n",
      "Collecting typing-extensions\n",
      "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting jinja2\n",
      "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /Users/shreyavinaynayak/miniconda3/lib/python3.10/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: numpy in /Users/shreyavinaynayak/miniconda3/lib/python3.10/site-packages (from torchvision) (1.25.2)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Downloading Pillow-10.0.1-cp310-cp310-macosx_11_0_arm64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.1.3-cp310-cp310-macosx_10_9_universal2.whl (17 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/shreyavinaynayak/miniconda3/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/shreyavinaynayak/miniconda3/lib/python3.10/site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/shreyavinaynayak/miniconda3/lib/python3.10/site-packages (from requests->torchvision) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/shreyavinaynayak/miniconda3/lib/python3.10/site-packages (from requests->torchvision) (2.0.4)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, typing-extensions, sympy, pillow, networkx, MarkupSafe, filelock, jinja2, torch, torchvision, torchaudio\n",
      "Successfully installed MarkupSafe-2.1.3 filelock-3.12.4 jinja2-3.1.2 mpmath-1.3.0 networkx-3.1 pillow-10.0.1 sympy-1.12 torch-2.0.1 torchaudio-2.0.2 torchvision-0.15.2 typing-extensions-4.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2359be",
   "metadata": {},
   "source": [
    "**Python Version: 3.10.12**\n",
    "\n",
    "**Library Versions** : \n",
    "\n",
    "----------------------------------------\n",
    "torch       : 2.0.1+cu118 \\\n",
    "gensim      : 4.3.2 \\\n",
    "tqdm        : 4.66.1 \\\n",
    "numpy       : 1.23.5 \\\n",
    "pandas      : 1.5.3 \\\n",
    "sklearn     : 1.2.2 \\\n",
    "torchvision : 0.15.2+cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b695248",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3b695248",
    "outputId": "0c666d4c-bf1a-4660-ae8b-dd58c8a4e714"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pickle\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus.reader.wordnet import NOUN, VERB, ADJ, ADV\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.linear_model import Perceptron,LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "import gensim.downloader as api\n",
    "import gensim\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "r5_Npg79GBl4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r5_Npg79GBl4",
    "outputId": "3c065d52-a138-4d9a-f6f8-8b49763a7a7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# As the notebook was run on colab to utilize GPUs, the following code cell has been commented out to make it executabele locally\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ceaf63",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c7ceaf63",
    "outputId": "60878fa8-61b7-4af4-96cc-325b1aa1d1cc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-f4a9d796f4e5>:2: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_table('/content/drive/MyDrive/Shreya Data/Shreya NLP/HW3/data.tsv',on_bad_lines='skip')\n"
     ]
    }
   ],
   "source": [
    "#Reading the tsv file\n",
    "# the line commented below was the one used for colab, un-commented line added for local execution\n",
    "# df = pd.read_table('/content/drive/MyDrive/Shreya Data/Shreya NLP/HW3/data.tsv',on_bad_lines='skip')\n",
    "#assuming that data.tsv is in the same directory as the notebook: \n",
    "df = pd.read_table('data.tsv',on_bad_lines = 'skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b66ca3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "f2b66ca3",
    "outputId": "01585783-8632-49d4-a194-532c0f9d9fed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-6625a7c9-d748-4c72-9fb1-0a72c075bef3\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>43081963</td>\n",
       "      <td>R18RVCKGH1SSI9</td>\n",
       "      <td>B001BM2MAC</td>\n",
       "      <td>307809868</td>\n",
       "      <td>Scotch Cushion Wrap 7961, 12 Inches x 100 Feet</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Great product.</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>10951564</td>\n",
       "      <td>R3L4L6LW1PUOFY</td>\n",
       "      <td>B00DZYEXPQ</td>\n",
       "      <td>75004341</td>\n",
       "      <td>Dust-Off Compressed Gas Duster, Pack of 4</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Phffffffft, Phfffffft. Lots of air, and it's C...</td>\n",
       "      <td>What's to say about this commodity item except...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>21143145</td>\n",
       "      <td>R2J8AWXWTDX2TF</td>\n",
       "      <td>B00RTMUHDW</td>\n",
       "      <td>529689027</td>\n",
       "      <td>Amram Tagger Standard Tag Attaching Tagging Gu...</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>but I am sure I will like it.</td>\n",
       "      <td>Haven't used yet, but I am sure I will like it.</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>52782374</td>\n",
       "      <td>R1PR37BR7G3M6A</td>\n",
       "      <td>B00D7H8XB6</td>\n",
       "      <td>868449945</td>\n",
       "      <td>AmazonBasics 12-Sheet High-Security Micro-Cut ...</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>and the shredder was dirty and the bin was par...</td>\n",
       "      <td>Although this was labeled as &amp;#34;new&amp;#34; the...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>24045652</td>\n",
       "      <td>R3BDDDZMZBZDPU</td>\n",
       "      <td>B001XCWP34</td>\n",
       "      <td>33521401</td>\n",
       "      <td>Derwent Colored Pencils, Inktense Ink Pencils,...</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>Gorgeous colors and easy to use</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6625a7c9-d748-4c72-9fb1-0a72c075bef3')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-6625a7c9-d748-4c72-9fb1-0a72c075bef3 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-6625a7c9-d748-4c72-9fb1-0a72c075bef3');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-0b8d6e69-3769-4c8e-9de0-8572f9baaa1e\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0b8d6e69-3769-4c8e-9de0-8572f9baaa1e')\"\n",
       "            title=\"Suggest charts.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-0b8d6e69-3769-4c8e-9de0-8572f9baaa1e button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US     43081963  R18RVCKGH1SSI9  B001BM2MAC       307809868   \n",
       "1          US     10951564  R3L4L6LW1PUOFY  B00DZYEXPQ        75004341   \n",
       "2          US     21143145  R2J8AWXWTDX2TF  B00RTMUHDW       529689027   \n",
       "3          US     52782374  R1PR37BR7G3M6A  B00D7H8XB6       868449945   \n",
       "4          US     24045652  R3BDDDZMZBZDPU  B001XCWP34        33521401   \n",
       "\n",
       "                                       product_title product_category  \\\n",
       "0     Scotch Cushion Wrap 7961, 12 Inches x 100 Feet  Office Products   \n",
       "1          Dust-Off Compressed Gas Duster, Pack of 4  Office Products   \n",
       "2  Amram Tagger Standard Tag Attaching Tagging Gu...  Office Products   \n",
       "3  AmazonBasics 12-Sheet High-Security Micro-Cut ...  Office Products   \n",
       "4  Derwent Colored Pencils, Inktense Ink Pencils,...  Office Products   \n",
       "\n",
       "  star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0           5            0.0          0.0    N                 Y   \n",
       "1           5            0.0          1.0    N                 Y   \n",
       "2           5            0.0          0.0    N                 Y   \n",
       "3           1            2.0          3.0    N                 Y   \n",
       "4           4            0.0          0.0    N                 Y   \n",
       "\n",
       "                                     review_headline  \\\n",
       "0                                         Five Stars   \n",
       "1  Phffffffft, Phfffffft. Lots of air, and it's C...   \n",
       "2                      but I am sure I will like it.   \n",
       "3  and the shredder was dirty and the bin was par...   \n",
       "4                                         Four Stars   \n",
       "\n",
       "                                         review_body review_date  \n",
       "0                                     Great product.  2015-08-31  \n",
       "1  What's to say about this commodity item except...  2015-08-31  \n",
       "2    Haven't used yet, but I am sure I will like it.  2015-08-31  \n",
       "3  Although this was labeled as &#34;new&#34; the...  2015-08-31  \n",
       "4                    Gorgeous colors and easy to use  2015-08-31  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29bd63a",
   "metadata": {
    "id": "e29bd63a"
   },
   "source": [
    "### Keep Reviews and Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f6769c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "53f6769c",
    "outputId": "03f2b930-b6c1-4b2c-9c3a-932227df49d6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-7d9acd4d4411>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.dropna(axis=0,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data = df[['star_rating','review_body']] #keeping only columns needed\n",
    "data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1040e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ee1040e9",
    "outputId": "b5204345-d160-4afb-a134-f0d01ff43947"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    1458992\n",
       "4     389603\n",
       "1     286072\n",
       "3     179867\n",
       "2     129031\n",
       "5     123770\n",
       "4      28757\n",
       "1      20896\n",
       "3      13819\n",
       "2       9350\n",
       "Name: star_rating, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['star_rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b1be47",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "53b1be47",
    "outputId": "b3326df9-d72d-47fb-c4aa-75239e70d336"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-7a970350aaa6>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['star_rating']=data['star_rating'].astype('int')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5    1582762\n",
       "4     418360\n",
       "1     306968\n",
       "3     193686\n",
       "2     138381\n",
       "Name: star_rating, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making all rows as integers\n",
    "data['star_rating']=data['star_rating'].astype('int')\n",
    "data['star_rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd431e85",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dd431e85",
    "outputId": "9b99b677-121c-4b65-ad20-b2435174c978"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-d096d57f7e16>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  class1['label'] = labels\n",
      "<ipython-input-9-d096d57f7e16>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  class2['label'] = labels\n"
     ]
    }
   ],
   "source": [
    "#splitting data into classes\n",
    "\n",
    "class1 = data[data['star_rating']<=3] #defining class 1 for ratings with values 1,2,3\n",
    "labels = [1]*len(class1)\n",
    "class1['label'] = labels\n",
    "\n",
    "class2 = data[data['star_rating']>=4]  #defining class 2 for ratings with values 4,5\n",
    "labels = [2]*len(class2)\n",
    "class2['label'] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe0a8c9",
   "metadata": {
    "id": "5fe0a8c9"
   },
   "source": [
    "### We form two classes and select 50000 reviews randomly from each class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bcb5b8",
   "metadata": {
    "id": "85bcb5b8"
   },
   "outputs": [],
   "source": [
    "# Sampling 50,000 random reviews from each class\n",
    "sampled_class1 = class1.sample(n=50000, random_state=42)  # Using a fixed random state for reproducibility\n",
    "sampled_class2 = class2.sample(n=50000, random_state=42)\n",
    "# Concatenating the sampled data to create a balanced dataset\n",
    "balanced_data = pd.concat([sampled_class1, sampled_class2], ignore_index=True)\n",
    "# Shuffle the dataset\n",
    "training_dataset = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641d924e",
   "metadata": {
    "id": "641d924e"
   },
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2840065",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "f2840065",
    "outputId": "650e982f-1186-4f83-bbe3-8ca187eaf95c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-4813c0c1-e0c2-4a8f-a08a-8d9c9d90efa9\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>the phone case is awesome  I've had other phon...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>perfect</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>fast delivery... grand daughter likes it</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>This is a great product.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Works great and so much cheaper than buying at...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4813c0c1-e0c2-4a8f-a08a-8d9c9d90efa9')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-4813c0c1-e0c2-4a8f-a08a-8d9c9d90efa9 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-4813c0c1-e0c2-4a8f-a08a-8d9c9d90efa9');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-8f94efab-3ab5-4221-ac92-86a7ac7e8cb9\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8f94efab-3ab5-4221-ac92-86a7ac7e8cb9')\"\n",
       "            title=\"Suggest charts.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-8f94efab-3ab5-4221-ac92-86a7ac7e8cb9 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   star_rating                                        review_body  label\n",
       "0            5  the phone case is awesome  I've had other phon...      2\n",
       "1            5                                            perfect      2\n",
       "2            1           fast delivery... grand daughter likes it      1\n",
       "3            5                           This is a great product.      2\n",
       "4            5  Works great and so much cheaper than buying at...      2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75092c7e",
   "metadata": {
    "id": "75092c7e"
   },
   "source": [
    "## Loading saved training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OQNwOlJyeVwu",
   "metadata": {
    "id": "OQNwOlJyeVwu"
   },
   "outputs": [],
   "source": [
    "# commented out as the same was stored in drive\n",
    "#training_dataset = pd.read_csv('/content/drive/MyDrive/Shreya Data/Shreya NLP/HW3/hw3_processed_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f190b943",
   "metadata": {
    "id": "f190b943"
   },
   "source": [
    "# TF-IDF and BoW Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9777e33",
   "metadata": {
    "id": "b9777e33"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "frequency_matrix = vectorizer.fit_transform(training_dataset['review_body'])\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "bow_features = count_vectorizer.fit_transform(training_dataset['review_body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95793a75",
   "metadata": {
    "id": "95793a75"
   },
   "outputs": [],
   "source": [
    "X_train_tf, X_test_tf, y_train_tf, y_test_tf = train_test_split(frequency_matrix, training_dataset['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dce158e",
   "metadata": {
    "id": "7dce158e"
   },
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327922d9",
   "metadata": {
    "id": "327922d9"
   },
   "source": [
    "### Loading Word2Vec model using GenSim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c9c3de",
   "metadata": {
    "id": "44c9c3de"
   },
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a5a0cf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "13a5a0cf",
    "outputId": "567aadca-22d6-4600-84e9-9c77204b5e51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from Google Drive.\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "# to save notebook memory, model was stored in drive to load directly. commented out for local execution \n",
    "\n",
    "# model_path = \"/content/drive/MyDrive/Shreya Data/Shreya NLP/HW3/word2vec_model.bin\"\n",
    "\n",
    "# # Check if model is already in Drive, if not, download and save\n",
    "# try:\n",
    "#     gen_word_2_vec = gensim.models.KeyedVectors.load(model_path)\n",
    "#     print(\"Model loaded from Google Drive.\")\n",
    "# except:\n",
    "#     print(\"Downloading model...\")\n",
    "#     gen_word_2_vec = api.load(\"word2vec-google-news-300\")\n",
    "#     gen_word_2_vec.save(model_path)\n",
    "#     print(\"Model saved to Google Drive.\")\n",
    "    \n",
    "#Loading word2vec model using gensim\n",
    "gen_word_2_vec = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "T5D2dTH76v9i",
   "metadata": {
    "id": "T5D2dTH76v9i"
   },
   "outputs": [],
   "source": [
    "gen_word_2_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d89541f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3d89541f",
    "outputId": "e6ee16b2-9fcd-4e31-a9f1-b3ff651f5644"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/3000000 is </s>\n",
      "word #1/3000000 is in\n",
      "word #2/3000000 is for\n",
      "word #3/3000000 is that\n",
      "word #4/3000000 is is\n",
      "word #5/3000000 is on\n",
      "word #6/3000000 is ##\n",
      "word #7/3000000 is The\n",
      "word #8/3000000 is with\n",
      "word #9/3000000 is said\n",
      "word #10/3000000 is was\n",
      "word #11/3000000 is the\n",
      "word #12/3000000 is at\n",
      "word #13/3000000 is not\n",
      "word #14/3000000 is as\n"
     ]
    }
   ],
   "source": [
    "#Loading the word2vec model to test the vocabulary\n",
    "words_to_print = 15\n",
    "vocabulary = gen_word_2_vec.index_to_key\n",
    "for index, word in enumerate(vocabulary[:words_to_print]):\n",
    "    print(f\"word #{index}/{len(vocabulary)} is {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef65e4a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ef65e4a8",
    "outputId": "486e92e3-f2e1-4440-d5c1-2980adc1b9ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118193507194519)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1: Checking king+woman-man=queen\n",
    "gen_word_2_vec.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78032f3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b78032f3",
    "outputId": "dfbed495-3df1-46c6-8752-e342c2916f4d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64131945"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2: checking similarity score of 2 similar words\n",
    "gen_word_2_vec.similarity(\"king\",\"monarch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808bfae6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "808bfae6",
    "outputId": "427bff2b-fb64-4ba4-a28c-0b361de7021b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55674857"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 3: checking similarity score of 2 similar words\n",
    "gen_word_2_vec.similarity(\"excellent\",\"outstanding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd1e90f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cfd1e90f",
    "outputId": "a9fdc772-5309-4f2e-8301-338bb4622e1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('daughter', 0.9154544472694397)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extra example\n",
    "gen_word_2_vec.most_similar(positive=['girl', 'son'], negative=['boy'], topn=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75cfe03",
   "metadata": {
    "id": "a75cfe03"
   },
   "source": [
    "### (b) Training a word2vec model on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764f6661",
   "metadata": {
    "id": "764f6661"
   },
   "outputs": [],
   "source": [
    "#splitting data into sentences to train the new model on the data\n",
    "sentences = [x.split() for x in training_dataset['review_body']]\n",
    "model = gensim.models.Word2Vec(sentences, vector_size=300, window=13, min_count=9)\n",
    "model.save('trained_model1.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c8d1f9",
   "metadata": {
    "id": "64c8d1f9"
   },
   "source": [
    "#### Check the semantic similarities for the same two examples in part (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8d78ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ad8d78ff",
    "outputId": "87a812d9-2d51-4288-cd6e-8e51c685a9dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('(many', 0.55901038646698)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing king+woman-man=queen\n",
    "model.wv.most_similar(positive=['woman','king'], negative=['man'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9600f8dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9600f8dd",
    "outputId": "dd84a3ea-f955-4585-c3bc-2938d0497379"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sister', 0.762198805809021)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['girl','son'], negative=['boy'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3991c315",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3991c315",
    "outputId": "37f3b590-86fe-4a47-b8fd-3eadc20bbce1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7482453"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same similarity\n",
    "model.wv.similarity(\"excellent\",\"outstanding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c89e1f2",
   "metadata": {
    "id": "8c89e1f2"
   },
   "source": [
    "#### What do you conclude from comparing vectors generated by yourself and the pretrained model?\n",
    "#### Which of the Word2Vec models seems to encode semantic similarities between words better?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d35a8b",
   "metadata": {
    "id": "b2d35a8b"
   },
   "source": [
    "Pre-trained model:\n",
    "king+woman-man = [('queen', 0.7118193507194519)] \\\n",
    "Similarity between excellent and outstanding: 0.5567486\n",
    "\n",
    "\n",
    "\n",
    "word2vec model trained on the dataset: \\\n",
    "king+woman-man = [('(many', 0.55901038646698)] \\\n",
    "Similarity between excellent and outstanding: 0.748253\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220b6510",
   "metadata": {
    "id": "220b6510"
   },
   "source": [
    "#### Conclusion:\n",
    "\n",
    "1) The pre-trained model appears to perform better in capturing semantic relationships and word similarities in the context of the specific vector arithmetic task (e.g., \"king + woman - man\").\n",
    "\n",
    "2) The model trained on the Amazon reviews dataset performs differently depending on the specific domain and data it was trained on. It appears to indicate a higher similarity between \"excellent\" and \"outstanding,\" which could be a reflection of the language usage patterns within the Amazon reviews dataset.\n",
    "\n",
    "3) The differences between the models may be attributed to variations in training data, dataset size, and domain-specific language patterns. Pre-trained models benefit from large and diverse datasets, which may contribute to their ability to capture more general semantic relationships. Model's performance is likely influenced by the characteristics of the Amazon reviews dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27584f17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "27584f17",
    "outputId": "7d341a0f-ca82-4bc8-cd78-5b12e6c84178"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing reviews: 100%|██████████| 100000/100000 [00:15<00:00, 6412.78it/s]\n"
     ]
    }
   ],
   "source": [
    "vector_size = gen_word_2_vec.vector_size\n",
    "index_to_key_set = set(gen_word_2_vec.index_to_key)  # converting to set for O(1) lookups\n",
    "\n",
    "# Generate a random non-zero vector for words not found in index_to_key_set\n",
    "random_vector = np.random.randn(vector_size)\n",
    "\n",
    "train_avg_vectors = [\n",
    "    np.mean([\n",
    "        gen_word_2_vec[word] if word in index_to_key_set else random_vector\n",
    "        for word in review.split()\n",
    "    ], axis=0)\n",
    "    for review in tqdm(training_dataset['review_body'], desc=\"Processing reviews\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79ebe78",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c79ebe78",
    "outputId": "d66dd9af-7146-461b-e99b-0853d3d920e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sum(np.isnan(train_avg_vectors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73f771f",
   "metadata": {
    "id": "f73f771f"
   },
   "outputs": [],
   "source": [
    "vectors = pd.DataFrame(np.vstack(train_avg_vectors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15ff938",
   "metadata": {
    "id": "e15ff938"
   },
   "outputs": [],
   "source": [
    "# To give every avg_vector corresponding label\n",
    "vectors['label'] = training_dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406e0b8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "406e0b8f",
    "outputId": "73e9f556-e681-49d9-8a0f-c18b5ffb74c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 301)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a6f6ef",
   "metadata": {
    "id": "e0a6f6ef"
   },
   "outputs": [],
   "source": [
    "#splitting into training and testing sets\n",
    "columns = list(vectors.columns)\n",
    "columns.remove('label')\n",
    "X_train,X_test,y_train,y_test = train_test_split(vectors[columns],vectors['label'],test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s19UvkIjQjQP",
   "metadata": {
    "id": "s19UvkIjQjQP"
   },
   "outputs": [],
   "source": [
    "del vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad31ee8",
   "metadata": {
    "id": "5ad31ee8"
   },
   "source": [
    "# Task 3 : Simple models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65009b36",
   "metadata": {
    "id": "65009b36"
   },
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef22a1e",
   "metadata": {
    "id": "2ef22a1e",
    "outputId": "1a594c38-17da-43e0-adc5-7f86aab028f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.86      0.87     10092\n",
      "           2       0.86      0.87      0.87      9908\n",
      "\n",
      "    accuracy                           0.87     20000\n",
      "   macro avg       0.87      0.87      0.87     20000\n",
      "weighted avg       0.87      0.87      0.87     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#training SVM on TFIDF\n",
    "svc_mod = LinearSVC() #(C=0.025, intercept_scaling = 1.0, max_iter = 10000000, tol = 1e-5)\n",
    "svc_mod.fit(X_train_tf,y_train_tf)\n",
    "svc_preds = svc_mod.predict(X_test_tf)\n",
    "print(classification_report(svc_preds,y_test_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f1574b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f8f1574b",
    "outputId": "9f71390c-b84c-4833-8ec6-45cb334ae968"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.78      0.81     10827\n",
      "           2       0.76      0.83      0.79      9173\n",
      "\n",
      "    accuracy                           0.80     20000\n",
      "   macro avg       0.80      0.80      0.80     20000\n",
      "weighted avg       0.80      0.80      0.80     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#training SVM on word2vec\n",
    "svc_mod = LinearSVC()\n",
    "svc_mod.fit(X_train,y_train)\n",
    "svc_preds = svc_mod.predict(X_test)\n",
    "print(classification_report(svc_preds,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533e67c3",
   "metadata": {
    "id": "533e67c3"
   },
   "source": [
    "#### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c30e9cd",
   "metadata": {
    "id": "5c30e9cd",
    "outputId": "9a889a95-8489-45b2-c09c-a7a6d5569647"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.67      0.77     13404\n",
      "           2       0.56      0.86      0.68      6596\n",
      "\n",
      "    accuracy                           0.73     20000\n",
      "   macro avg       0.73      0.76      0.72     20000\n",
      "weighted avg       0.79      0.73      0.74     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training perceptron on tfidf\n",
    "perceptron = Perceptron(alpha = 0.00065,max_iter = 100000, penalty = 'elasticnet',tol=0.000001, l1_ratio=0.25)\n",
    "perceptron.fit(X_train_tf,y_train_tf)\n",
    "percep_preds = perceptron.predict(X_test_tf)\n",
    "print(classification_report(percep_preds,y_test_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6083bf15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6083bf15",
    "outputId": "d86eb4ef-bee7-43df-9aa2-868bed6c4733"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.80      0.71      7985\n",
      "           2       0.84      0.70      0.77     12015\n",
      "\n",
      "    accuracy                           0.74     20000\n",
      "   macro avg       0.74      0.75      0.74     20000\n",
      "weighted avg       0.76      0.74      0.74     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training perceptron on word2vec\n",
    "perceptron = Perceptron(alpha = 0.00065,max_iter = 100000, penalty = 'elasticnet',tol=0.000001, l1_ratio=0.25) #(alpha = 0.000035,max_iter = 100000, penalty = 'elasticnet',tol=0.0001, l1_ratio=0.1)\n",
    "perceptron.fit(X_train,y_train)\n",
    "percep_preds = perceptron.predict(X_test)\n",
    "print(classification_report(percep_preds,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31d8997",
   "metadata": {
    "id": "e31d8997"
   },
   "source": [
    "#### Accuracy Scores:\n",
    "##### Using TFIDF:\n",
    "SVM accuracy =87% \\\n",
    "Perceptron accuracy = 73%\n",
    "##### Using word2vec:\n",
    "SVM accuracy =80% \\\n",
    "Perceptron accuracy =74%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f23bc29",
   "metadata": {
    "id": "3f23bc29"
   },
   "source": [
    "#### What do you conclude from comparing performances for the models trained using the two different feature types (TF-IDF and your trained Word2Vec features)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01911395",
   "metadata": {
    "id": "01911395"
   },
   "source": [
    "1) The Perceptron classifier achieved a higher accuracy of 74% when using Word2Vec features compared to the 73% accuracy achieved with TF-IDF features.\n",
    "This suggests that, for the specific classification task and dataset, Word2Vec features were more effective in capturing relevant information and patterns for the Perceptron classifier.\n",
    "\n",
    "2)SVM with TF-IDF achieved an accuracy of 87%, which was the highest among all the models tested.\n",
    "\n",
    "\n",
    "3) SVM vs. Perceptron: In general, the SVM classifier tends to perform better than the Perceptron classifier in this task, regardless of the feature type used. This could be due to the SVM's ability to handle non-linear relationships in the data and find better decision boundaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1dc04e",
   "metadata": {
    "id": "5a1dc04e"
   },
   "source": [
    "# Task 4 : Feedforward Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c90f38",
   "metadata": {
    "id": "d1c90f38"
   },
   "source": [
    "#### 4a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bba9ca",
   "metadata": {
    "id": "18bba9ca"
   },
   "outputs": [],
   "source": [
    "#data generator and dataloader from word2vec data\n",
    "nn_training_data = torch.from_numpy(X_train.astype('float32').to_numpy()) #float32 to match model weight dtypes\n",
    "nn_testing_data = torch.from_numpy(X_test.astype('float32').to_numpy())\n",
    "nn_training_label = torch.from_numpy((y_train-1).astype('long').to_numpy())\n",
    "nn_testing_label = torch.from_numpy((y_test-1).astype('long').to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d8cf22",
   "metadata": {
    "id": "c0d8cf22"
   },
   "outputs": [],
   "source": [
    "# Defining data loaders\n",
    "training_data_td = torch.utils.data.TensorDataset(nn_training_data,nn_training_label)\n",
    "testing_data_td = torch.utils.data.TensorDataset(nn_testing_data,nn_testing_label)\n",
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(training_data_td,batch_size = batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(testing_data_td,batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea93f64",
   "metadata": {
    "id": "5ea93f64"
   },
   "outputs": [],
   "source": [
    "#testing the dataloaders\n",
    "X,y = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553484dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "553484dd",
    "outputId": "7dcd39c3-e76f-4f3e-df57-40a98cd44e10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc09a42e",
   "metadata": {
    "id": "fc09a42e"
   },
   "outputs": [],
   "source": [
    "# defining model:\n",
    "class FNN_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FNN_model,self).__init__()\n",
    "        self.fc1 = nn.Linear(300,50) #input size, hidden 1 size\n",
    "        self.fc2 = nn.Linear(50,5) #hidden 1 size, hidden 2 size\n",
    "        self.fc3 = nn.Linear(5,2) #hidden 2 size, output size (since 2 classes)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self,X):\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = self.dropout(X)\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = self.dropout(X)\n",
    "        X = self.fc3(X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a7e4a3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3a7e4a3",
    "outputId": "dbe74c2f-7283-410a-b643-ca3106fac977"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FNN_model(\n",
       "  (fc1): Linear(in_features=300, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=5, bias=True)\n",
       "  (fc3): Linear(in_features=5, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FNN_model()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb27bb7f",
   "metadata": {
    "id": "cb27bb7f"
   },
   "outputs": [],
   "source": [
    "lr = 0.0003\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1fdeea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5a1fdeea",
    "outputId": "fb12cbf1-21ca-430e-a1b0-10ce1482b9d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.722175 \tTest Loss: 0.710218\n"
     ]
    }
   ],
   "source": [
    "# test run:\n",
    "\n",
    "epochs = 1\n",
    "for e in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "    model.train() # prep model for training\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "#         print(\"got here!\")\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "    model.eval() # prep model for evaluation\n",
    "    for data, target in test_loader:\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        test_loss += loss.item()*data.size(0)\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    test_loss = test_loss/len(test_loader.dataset)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tTest Loss: {:.6f}'.format(\n",
    "        e+1,\n",
    "        train_loss,\n",
    "        test_loss\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ebca91",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "94ebca91",
    "outputId": "172c37e8-8079-4bd2-e6a2-1486b92a5104"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Epoch: 1 \tTraining Loss: 0.696178 \tTest Loss: 0.694661\n",
      "Epoch: 11 \tTraining Loss: 0.692336 \tTest Loss: 0.692217\n",
      "Epoch: 21 \tTraining Loss: 0.691742 \tTest Loss: 0.691581\n",
      "Epoch: 31 \tTraining Loss: 0.690905 \tTest Loss: 0.690775\n",
      "Epoch: 41 \tTraining Loss: 0.689935 \tTest Loss: 0.689636\n",
      "Epoch: 51 \tTraining Loss: 0.688408 \tTest Loss: 0.687989\n",
      "Epoch: 61 \tTraining Loss: 0.686348 \tTest Loss: 0.685560\n",
      "Epoch: 71 \tTraining Loss: 0.683010 \tTest Loss: 0.681924\n",
      "Epoch: 81 \tTraining Loss: 0.678379 \tTest Loss: 0.676569\n",
      "Epoch: 91 \tTraining Loss: 0.672584 \tTest Loss: 0.669058\n",
      "Epoch: 101 \tTraining Loss: 0.664093 \tTest Loss: 0.658559\n",
      "Epoch: 111 \tTraining Loss: 0.651827 \tTest Loss: 0.643788\n",
      "Epoch: 121 \tTraining Loss: 0.635033 \tTest Loss: 0.624615\n",
      "Epoch: 131 \tTraining Loss: 0.618467 \tTest Loss: 0.603940\n",
      "Epoch: 141 \tTraining Loss: 0.601047 \tTest Loss: 0.581399\n",
      "Epoch: 151 \tTraining Loss: 0.585286 \tTest Loss: 0.560688\n",
      "Epoch: 161 \tTraining Loss: 0.572609 \tTest Loss: 0.543480\n",
      "Epoch: 171 \tTraining Loss: 0.563015 \tTest Loss: 0.529003\n",
      "Epoch: 181 \tTraining Loss: 0.553458 \tTest Loss: 0.519381\n",
      "Epoch: 191 \tTraining Loss: 0.546436 \tTest Loss: 0.508227\n",
      "Epoch: 201 \tTraining Loss: 0.539658 \tTest Loss: 0.502138\n",
      "Epoch: 211 \tTraining Loss: 0.536443 \tTest Loss: 0.497476\n",
      "Epoch: 221 \tTraining Loss: 0.531746 \tTest Loss: 0.489759\n",
      "Epoch: 231 \tTraining Loss: 0.529910 \tTest Loss: 0.484286\n",
      "Epoch: 241 \tTraining Loss: 0.524126 \tTest Loss: 0.482563\n",
      "Epoch: 251 \tTraining Loss: 0.521110 \tTest Loss: 0.477601\n",
      "Epoch: 261 \tTraining Loss: 0.519608 \tTest Loss: 0.473678\n",
      "Epoch: 271 \tTraining Loss: 0.516708 \tTest Loss: 0.474068\n",
      "Epoch: 281 \tTraining Loss: 0.511676 \tTest Loss: 0.467757\n",
      "Epoch: 291 \tTraining Loss: 0.511499 \tTest Loss: 0.465532\n",
      "Epoch: 301 \tTraining Loss: 0.510427 \tTest Loss: 0.464054\n",
      "Epoch: 311 \tTraining Loss: 0.508241 \tTest Loss: 0.461719\n",
      "Epoch: 321 \tTraining Loss: 0.504818 \tTest Loss: 0.459887\n",
      "Epoch: 331 \tTraining Loss: 0.505548 \tTest Loss: 0.458676\n",
      "Epoch: 341 \tTraining Loss: 0.501971 \tTest Loss: 0.456807\n",
      "Epoch: 351 \tTraining Loss: 0.503334 \tTest Loss: 0.454549\n",
      "Epoch: 361 \tTraining Loss: 0.501377 \tTest Loss: 0.454236\n",
      "Epoch: 371 \tTraining Loss: 0.499151 \tTest Loss: 0.452093\n",
      "Epoch: 381 \tTraining Loss: 0.498956 \tTest Loss: 0.452266\n",
      "Epoch: 391 \tTraining Loss: 0.498021 \tTest Loss: 0.449631\n",
      "Epoch: 401 \tTraining Loss: 0.497400 \tTest Loss: 0.448998\n",
      "Epoch: 411 \tTraining Loss: 0.495081 \tTest Loss: 0.447477\n",
      "Epoch: 421 \tTraining Loss: 0.497334 \tTest Loss: 0.447458\n",
      "Epoch: 431 \tTraining Loss: 0.494475 \tTest Loss: 0.446502\n",
      "Epoch: 441 \tTraining Loss: 0.494180 \tTest Loss: 0.445272\n",
      "Epoch: 451 \tTraining Loss: 0.492050 \tTest Loss: 0.444436\n",
      "Epoch: 461 \tTraining Loss: 0.492393 \tTest Loss: 0.445070\n",
      "Epoch: 471 \tTraining Loss: 0.490891 \tTest Loss: 0.443078\n",
      "Epoch: 481 \tTraining Loss: 0.491048 \tTest Loss: 0.442484\n",
      "Epoch: 491 \tTraining Loss: 0.491162 \tTest Loss: 0.442129\n",
      "Epoch: 501 \tTraining Loss: 0.489568 \tTest Loss: 0.441786\n",
      "Epoch: 511 \tTraining Loss: 0.489846 \tTest Loss: 0.440740\n",
      "Epoch: 521 \tTraining Loss: 0.490746 \tTest Loss: 0.442886\n",
      "Epoch: 531 \tTraining Loss: 0.491148 \tTest Loss: 0.440015\n",
      "Epoch: 541 \tTraining Loss: 0.485854 \tTest Loss: 0.439283\n",
      "Epoch: 551 \tTraining Loss: 0.486144 \tTest Loss: 0.438758\n",
      "Epoch: 561 \tTraining Loss: 0.486752 \tTest Loss: 0.438547\n",
      "Epoch: 571 \tTraining Loss: 0.486919 \tTest Loss: 0.440276\n",
      "Epoch: 581 \tTraining Loss: 0.486404 \tTest Loss: 0.439822\n",
      "Epoch: 591 \tTraining Loss: 0.485436 \tTest Loss: 0.438573\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA (GPU) is available and set the device accordingly - utilizing colab's GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = model.to(device)  # Move model to the selected device\n",
    "#600 so far\n",
    "epochs = 600\n",
    "for e in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "    model.train()  # prep model for training\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        # Move data and target to the selected device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "\n",
    "    model.eval()  # prep model for evaluation\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        # Move data and target to the selected device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        test_loss += loss.item() * data.size(0)\n",
    "\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "\n",
    "    if e % 10 == 0:\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tTest Loss: {:.6f}'.format(\n",
    "            e + 1,\n",
    "            train_loss,\n",
    "            test_loss\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaab711",
   "metadata": {
    "id": "beaab711"
   },
   "outputs": [],
   "source": [
    "with open(\"model1.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312082a8",
   "metadata": {
    "id": "312082a8"
   },
   "source": [
    "#### Accuracy 4 a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83effc4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a83effc4",
    "outputId": "58463d8b-d135-4599-b24f-fb6cac1be0e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8118\n"
     ]
    }
   ],
   "source": [
    "#calculating accuracy\n",
    "preds = []\n",
    "labels=[]\n",
    "for data,target in test_loader:\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    output = model(data)\n",
    "    preds += list(torch.argmax(output,dim=1).cpu())\n",
    "    labels += list(target.cpu())\n",
    "    # preds.append(torch.argmax(output,dim=1).cpu())\n",
    "    # labels.append(target[0].cpu())\n",
    "print(\"Accuracy: \",accuracy_score(preds,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UDbTYd1Aciao",
   "metadata": {
    "id": "UDbTYd1Aciao"
   },
   "outputs": [],
   "source": [
    "# freeing some memory to avoid memory crashes:\n",
    "# del train_loader\n",
    "# del test_loader\n",
    "# del training_data_td\n",
    "# del testing_data_td\n",
    "# del nn_training_data\n",
    "# del nn_testing_data\n",
    "# del nn_training_label\n",
    "# del nn_testing_label\n",
    "# del train_avg_vectors\n",
    "# del model\n",
    "# del svc_mod\n",
    "# del perceptron\n",
    "# del vocabulary\n",
    "# del vectors\n",
    "# del X_train,X_test,y_train,y_test\n",
    "# del gen_word_2_vec\n",
    "# del optimizer,criterion\n",
    "# del preds,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc463de3",
   "metadata": {
    "id": "dc463de3"
   },
   "source": [
    "#### 4 b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f95f763",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0f95f763",
    "outputId": "7c1b687a-bdb2-43c3-df96-b799decec47d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing reviews: 100%|██████████| 100000/100000 [00:04<00:00, 24572.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# #processing data again for 4b:\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Assuming vector_size is defined\n",
    "vector_size = 300  # assuming this size\n",
    "random_vector = np.random.randn(vector_size)\n",
    "\n",
    "# Create a set for O(1) lookup complexity\n",
    "index_to_key_set = set(gen_word_2_vec.index_to_key)\n",
    "\n",
    "def process_review(review):\n",
    "    words = review.split()[:10]\n",
    "    res = np.zeros((10, vector_size))\n",
    "\n",
    "    for idx, word in enumerate(words):\n",
    "        res[idx] = gen_word_2_vec[word] if word in index_to_key_set else random_vector\n",
    "\n",
    "    return res.flatten()\n",
    "\n",
    "# Process all reviews using a list comprehension within np.array which is more memory efficient and faster\n",
    "new_train_vectors = np.array([process_review(review) for review in tqdm(training_dataset['review_body'], desc=\"Processing reviews\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KdWDxkYpUQ87",
   "metadata": {
    "id": "KdWDxkYpUQ87"
   },
   "outputs": [],
   "source": [
    "del gen_word_2_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba781ce3",
   "metadata": {
    "id": "ba781ce3"
   },
   "outputs": [],
   "source": [
    "new_train_vectors = np.array(new_train_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e23dd0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "64e23dd0",
    "outputId": "9e694894-d39c-435e-ddff-1e77fb5762e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 3000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e805c0",
   "metadata": {
    "id": "31e805c0"
   },
   "outputs": [],
   "source": [
    "#making a DataFrame for the new vectors, and making training and testing sets\n",
    "n_vectors = pd.DataFrame(new_train_vectors)\n",
    "n_vectors['label']=training_dataset['label']\n",
    "columns = list(n_vectors.columns)\n",
    "columns.remove('label')\n",
    "X_train_n,X_test_n,y_train_n,y_test_n = train_test_split(n_vectors[columns],n_vectors['label'],test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "N2kY02z3UoE1",
   "metadata": {
    "id": "N2kY02z3UoE1"
   },
   "outputs": [],
   "source": [
    "del new_train_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8543f954",
   "metadata": {
    "id": "8543f954"
   },
   "outputs": [],
   "source": [
    "#data generator and dataloader\n",
    "nn_train_data_n = torch.from_numpy(X_train_n.astype('float32').to_numpy())\n",
    "nn_test_data_n = torch.from_numpy(X_test_n.astype('float32').to_numpy())\n",
    "nn_train_label_n = torch.from_numpy((y_train_n-1).astype('long').to_numpy())\n",
    "nn_test_label_n = torch.from_numpy((y_test_n-1).astype('long').to_numpy())\n",
    "#making a tensor dataset for data loaders\n",
    "train_data_td_n = torch.utils.data.TensorDataset(nn_train_data_n,nn_train_label_n)\n",
    "test_data_td_n = torch.utils.data.TensorDataset(nn_test_data_n,nn_test_label_n)\n",
    "# Defining data loaders\n",
    "train_loader_n = torch.utils.data.DataLoader(train_data_td_n,batch_size = 32)\n",
    "test_loader_n = torch.utils.data.DataLoader(test_data_td_n,batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PWyPIQPIiHLv",
   "metadata": {
    "id": "PWyPIQPIiHLv"
   },
   "outputs": [],
   "source": [
    "class FNN_model_b(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FNN_model_b,self).__init__()\n",
    "        self.fc1 = nn.Linear(3000,50) #input size, hidden 1 size\n",
    "        self.fc2 = nn.Linear(50,5) #hidden 1 size, hidden 2 size\n",
    "        self.fc3 = nn.Linear(5,2) #hidden 2 size, output size (since 2 classes)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self,X):\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = self.dropout(X)\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = self.dropout(X)\n",
    "        X = self.fc3(X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff87477a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ff87477a",
    "outputId": "be7be092-09a5-4448-b036-3edf4fc9fa46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FNN_model_b(\n",
       "  (fc1): Linear(in_features=3000, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=5, bias=True)\n",
       "  (fc3): Linear(in_features=5, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the same model:\n",
    "model_b = FNN_model_b()\n",
    "model_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37617f8",
   "metadata": {
    "id": "e37617f8"
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_b.parameters(),lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18db90c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c18db90c",
    "outputId": "5308464f-1281-474a-b237-01a568ea8c6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.694562 \tTest Loss: 0.692958\n",
      "Epoch: 11 \tTraining Loss: 0.664800 \tTest Loss: 0.656524\n",
      "Epoch: 21 \tTraining Loss: 0.578206 \tTest Loss: 0.556272\n",
      "Epoch: 31 \tTraining Loss: 0.549619 \tTest Loss: 0.529982\n",
      "Epoch: 41 \tTraining Loss: 0.534888 \tTest Loss: 0.522288\n",
      "Epoch: 51 \tTraining Loss: 0.522040 \tTest Loss: 0.513575\n",
      "Epoch: 61 \tTraining Loss: 0.513433 \tTest Loss: 0.513215\n",
      "Epoch: 71 \tTraining Loss: 0.503665 \tTest Loss: 0.506810\n",
      "Epoch: 81 \tTraining Loss: 0.494552 \tTest Loss: 0.506960\n",
      "Epoch: 91 \tTraining Loss: 0.485505 \tTest Loss: 0.510946\n",
      "Epoch: 101 \tTraining Loss: 0.476249 \tTest Loss: 0.506060\n",
      "Epoch: 111 \tTraining Loss: 0.465394 \tTest Loss: 0.502586\n",
      "Epoch: 121 \tTraining Loss: 0.454896 \tTest Loss: 0.509016\n",
      "Epoch: 131 \tTraining Loss: 0.443605 \tTest Loss: 0.517942\n",
      "Epoch: 141 \tTraining Loss: 0.434916 \tTest Loss: 0.515151\n",
      "Epoch: 151 \tTraining Loss: 0.421908 \tTest Loss: 0.523124\n",
      "Epoch: 161 \tTraining Loss: 0.411221 \tTest Loss: 0.516478\n",
      "Epoch: 171 \tTraining Loss: 0.401773 \tTest Loss: 0.528936\n",
      "Epoch: 181 \tTraining Loss: 0.389829 \tTest Loss: 0.542731\n",
      "Epoch: 191 \tTraining Loss: 0.377702 \tTest Loss: 0.549939\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "for e in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "    model_b.train() # prep model for training\n",
    "    for data, target in train_loader_n:\n",
    "        optimizer.zero_grad()\n",
    "        output = model_b(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "    model_b.eval() # prep model for evaluation\n",
    "    for data, target in test_loader_n:\n",
    "        output = model_b(data)\n",
    "        loss = criterion(output, target)\n",
    "        test_loss += loss.item()*data.size(0)\n",
    "    train_loss = train_loss/len(train_loader_n.dataset)\n",
    "    test_loss = test_loss/len(test_loader_n.dataset)\n",
    "    if e%10 ==0:\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tTest Loss: {:.6f}'.format(\n",
    "        e+1,\n",
    "        train_loss,\n",
    "        test_loss\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2132e62e",
   "metadata": {
    "id": "2132e62e"
   },
   "outputs": [],
   "source": [
    "with open(\"model2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9584f356",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9584f356",
    "outputId": "a9cc98d7-22b5-4b1e-f420-a7a42b32da35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.743\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "labels=[]\n",
    "for data,target in test_loader_n:\n",
    "    # data, target = data.to(device), target.to(device)\n",
    "    output = model_b(data)\n",
    "    preds += list(torch.argmax(output,dim=1).cpu())\n",
    "    labels += list(target.cpu())\n",
    "    # preds.append(torch.argmax(output,dim=1).cpu())\n",
    "    # labels.append(target[0].cpu())\n",
    "print(\"Accuracy: \",accuracy_score(preds,labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YhTrNVLlarWg",
   "metadata": {
    "id": "YhTrNVLlarWg"
   },
   "source": [
    "**Conclusion on training MLP**: \\\n",
    "The MLP models achieved an accuracy of around 82%(averaged word2vec feautures) and around 75% (features of 10 words), both of which are better than the Perceptron and comparable to the SVM's performance. We can conlcude that the MLP generalizes better over averaged Word2Vec features than the sklearn models.\n",
    "\n",
    "A possible reason why the second MLP accuracy is lower than the first could be that important information about the sentiment of a review might be more in the latter part of the reviews with length > 10, which might be represented more in the averaged vectors (training data of the 4 a). Since potentially better data may have been fed to the first MLP, it was able to perform better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd487d8",
   "metadata": {
    "id": "9dd487d8"
   },
   "source": [
    "# Task 5 : Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97a3f0d",
   "metadata": {
    "id": "e97a3f0d"
   },
   "source": [
    "#### 5 a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f9ffb8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23f9ffb8",
    "outputId": "110e6a43-96f7-40dc-84db-19c94241adf3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing reviews: 100%|██████████| 100000/100000 [00:05<00:00, 17023.70it/s]\n"
     ]
    }
   ],
   "source": [
    "def vectorize_reviews(reviews, word2vec, max_words=10, vector_size=300):\n",
    "    num_reviews = len(reviews)\n",
    "    vectors = np.zeros((num_reviews, max_words, vector_size))\n",
    "\n",
    "    word2vec_keys = set(word2vec.index_to_key)  # Precompute this\n",
    "    random_vector = np.random.randn(vector_size)  # Predefined random vector\n",
    "\n",
    "    for i, review in enumerate(tqdm(reviews, desc=\"Vectorizing reviews\")):\n",
    "        words = review.split()[:max_words]\n",
    "\n",
    "        # Efficiently assign word vectors or random_vector based on condition\n",
    "        vectors[i, :len(words)] = [word2vec[word] if word in word2vec_keys else random_vector for word in words]\n",
    "\n",
    "    return vectors\n",
    "\n",
    "new_train_vectors_5 = vectorize_reviews(training_dataset['review_body'], gen_word_2_vec)\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "X_train_5, X_test_5, y_train_5, y_test_5 = train_test_split(\n",
    "    new_train_vectors_5,\n",
    "    training_dataset['label'],\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DeEjsSgny-T5",
   "metadata": {
    "id": "DeEjsSgny-T5"
   },
   "outputs": [],
   "source": [
    "del gen_word_2_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ubk0R7C_Z0Zh",
   "metadata": {
    "id": "Ubk0R7C_Z0Zh"
   },
   "outputs": [],
   "source": [
    "del training_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KUauWuxjaxEj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "KUauWuxjaxEj",
    "outputId": "b60d9d12-6361-41df-b056-7db142322f75"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-d030024f95ab>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Convert to Torch tensors and free up memory immediately after conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mnn_train_data_5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mX_train_5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_5' is not defined"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "# Convert to Torch tensors and free up memory immediately after conversion to save RAM\n",
    "nn_train_data_5 = torch.from_numpy(X_train_5.astype('float32'))\n",
    "del X_train_5\n",
    "gc.collect()\n",
    "\n",
    "nn_test_data_5 = torch.from_numpy(X_test_5.astype('float32'))\n",
    "del X_test_5\n",
    "gc.collect()\n",
    "\n",
    "nn_train_label_5 = torch.from_numpy((y_train_5 - 1).astype('long').to_numpy())\n",
    "del y_train_5\n",
    "gc.collect()\n",
    "\n",
    "nn_test_label_5 = torch.from_numpy((y_test_5 - 1).astype('long').to_numpy())\n",
    "del y_test_5\n",
    "gc.collect()\n",
    "\n",
    "train_data_td_5 = torch.utils.data.TensorDataset(nn_train_data_5, nn_train_label_5)\n",
    "test_data_td_5 = torch.utils.data.TensorDataset(nn_test_data_5, nn_test_label_5)\n",
    "\n",
    "BATCH_SIZE = 32  # Adjusted according to available memory\n",
    "train_loader_5 = torch.utils.data.DataLoader(train_data_td_5, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader_5 = torch.utils.data.DataLoader(test_data_td_5, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c684538e",
   "metadata": {
    "id": "c684538e"
   },
   "outputs": [],
   "source": [
    "class RNN_5a(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        super(RNN_5a, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "#         self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "        self. softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         x = self.embedding(x)\n",
    "        # h0 = torch.zeros(1, x.size(0), self.rnn.hidden_size)\n",
    "        h0 = torch.zeros(1, x.size(0), self.rnn.hidden_size).to(x.device)\n",
    "\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        out = self.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d83c8fb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8d83c8fb",
    "outputId": "208c1dde-b39f-4a66-a0ea-fd0f0551b4e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN_5a(\n",
       "  (rnn): RNN(300, 10, batch_first=True)\n",
       "  (fc): Linear(in_features=10, out_features=2, bias=True)\n",
       "  (softmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_task5a = RNN_5a(300,10,2)\n",
    "model_task5a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf6cf71",
   "metadata": {
    "id": "bcf6cf71"
   },
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_task5a.parameters(),lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9gcS30L3-lzK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9gcS30L3-lzK",
    "outputId": "8972fcdb-3a0a-4804-ebf1-e86e9e0e7cc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0\n",
      "Epoch: 1 \tTraining Loss: 0.504585 \tTest Loss: 0.508744\n",
      "Epoch: 6 \tTraining Loss: 0.504546 \tTest Loss: 0.509365\n",
      "Epoch: 11 \tTraining Loss: 0.504347 \tTest Loss: 0.508746\n",
      "Epoch: 16 \tTraining Loss: 0.504238 \tTest Loss: 0.508798\n",
      "Epoch: 21 \tTraining Loss: 0.504215 \tTest Loss: 0.508271\n",
      "Epoch: 26 \tTraining Loss: 0.504068 \tTest Loss: 0.508333\n",
      "Epoch: 31 \tTraining Loss: 0.503989 \tTest Loss: 0.508120\n",
      "Epoch: 36 \tTraining Loss: 0.503887 \tTest Loss: 0.507966\n",
      "Epoch: 41 \tTraining Loss: 0.503641 \tTest Loss: 0.508122\n",
      "Epoch: 46 \tTraining Loss: 0.503587 \tTest Loss: 0.507697\n",
      "Epoch: 51 \tTraining Loss: 0.503555 \tTest Loss: 0.507855\n",
      "Epoch: 56 \tTraining Loss: 0.503368 \tTest Loss: 0.508104\n",
      "Epoch: 61 \tTraining Loss: 0.503274 \tTest Loss: 0.507600\n",
      "Epoch: 66 \tTraining Loss: 0.503149 \tTest Loss: 0.507688\n",
      "Epoch: 71 \tTraining Loss: 0.503140 \tTest Loss: 0.507589\n",
      "Epoch: 76 \tTraining Loss: 0.502985 \tTest Loss: 0.507588\n",
      "Epoch: 81 \tTraining Loss: 0.502946 \tTest Loss: 0.507426\n",
      "Epoch: 86 \tTraining Loss: 0.502778 \tTest Loss: 0.507607\n",
      "Epoch: 91 \tTraining Loss: 0.502755 \tTest Loss: 0.507629\n",
      "Epoch: 96 \tTraining Loss: 0.502574 \tTest Loss: 0.506947\n",
      "Epoch: 101 \tTraining Loss: 0.502560 \tTest Loss: 0.506815\n",
      "Epoch: 106 \tTraining Loss: 0.502551 \tTest Loss: 0.507210\n",
      "Epoch: 111 \tTraining Loss: 0.502267 \tTest Loss: 0.508302\n",
      "Epoch: 116 \tTraining Loss: 0.502142 \tTest Loss: 0.506997\n",
      "Epoch: 121 \tTraining Loss: 0.502177 \tTest Loss: 0.506985\n",
      "Epoch: 126 \tTraining Loss: 0.501948 \tTest Loss: 0.506867\n",
      "Epoch: 131 \tTraining Loss: 0.501922 \tTest Loss: 0.506495\n",
      "Epoch: 136 \tTraining Loss: 0.501804 \tTest Loss: 0.506812\n",
      "Epoch: 141 \tTraining Loss: 0.501665 \tTest Loss: 0.506625\n",
      "Epoch: 146 \tTraining Loss: 0.501623 \tTest Loss: 0.506501\n",
      "Epoch: 151 \tTraining Loss: 0.501572 \tTest Loss: 0.506403\n",
      "Epoch: 156 \tTraining Loss: 0.501436 \tTest Loss: 0.506130\n",
      "Epoch: 161 \tTraining Loss: 0.501271 \tTest Loss: 0.506522\n",
      "Epoch: 166 \tTraining Loss: 0.501219 \tTest Loss: 0.506462\n",
      "Epoch: 171 \tTraining Loss: 0.501150 \tTest Loss: 0.506607\n",
      "Epoch: 176 \tTraining Loss: 0.501036 \tTest Loss: 0.506217\n",
      "Epoch: 181 \tTraining Loss: 0.500897 \tTest Loss: 0.505907\n",
      "Epoch: 186 \tTraining Loss: 0.500754 \tTest Loss: 0.505595\n",
      "Epoch: 191 \tTraining Loss: 0.500796 \tTest Loss: 0.505525\n",
      "Epoch: 196 \tTraining Loss: 0.500676 \tTest Loss: 0.505571\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {device}\")\n",
    "#1400\n",
    "# Move the model to the device\n",
    "model_task5a.to(device)\n",
    "\n",
    "epochs = 200\n",
    "for e in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "\n",
    "    model_task5a.train()  # prep model for training\n",
    "\n",
    "    for data, target in train_loader_5:\n",
    "        # Move data and target labels to the device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model_task5a(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "\n",
    "    model_task5a.eval()  # prep model for evaluation\n",
    "\n",
    "    for data, target in test_loader_5:\n",
    "        # Move data and target labels to the device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output = model_task5a(data)\n",
    "        loss = criterion(output, target)\n",
    "        test_loss += loss.item() * data.size(0)\n",
    "\n",
    "    train_loss = train_loss / len(train_loader_5.dataset)\n",
    "    test_loss = test_loss / len(test_loader_5.dataset)\n",
    "\n",
    "    if e % 5 == 0:\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tTest Loss: {:.6f}'.format(\n",
    "            e + 1,\n",
    "            train_loss,\n",
    "            test_loss\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ff617e",
   "metadata": {
    "id": "89ff617e"
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"model1_5a.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(model_task5a.cpu(), f)\n",
    "torch.save(model_task5a.state_dict(), 'model_task5a.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "R7Jw9aN4sgKp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R7Jw9aN4sgKp",
    "outputId": "e4ec603b-1ac9-438d-e640-2f8cc5d14006"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.75195\n"
     ]
    }
   ],
   "source": [
    "#calculating accuracy\n",
    "preds = []\n",
    "labels=[]\n",
    "for data,target in test_loader_5:\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    output = model_task5a(data)\n",
    "    preds += list(torch.argmax(output,dim=1).cpu())\n",
    "    labels += list(target.cpu())\n",
    "    # preds.append(torch.argmax(output,dim=1).cpu())\n",
    "    # labels.append(target[0].cpu())\n",
    "print(\"Accuracy: \",accuracy_score(preds,labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SUx4bKjmb5JY",
   "metadata": {
    "id": "SUx4bKjmb5JY"
   },
   "source": [
    "**Conclusion on training with simple RNN:**\n",
    "The RNN achieved better accuracy compared to the MLP models, when fed with features of the first 10 words. It could be because the RNN captures generality over Word2Vec features better than the MLP (or simple FNN). The architecture of RNN may be the reason why it performs better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac259bd",
   "metadata": {
    "id": "3ac259bd"
   },
   "source": [
    "#### 5b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac8f239",
   "metadata": {
    "id": "aac8f239"
   },
   "outputs": [],
   "source": [
    "class RNN_5b(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        super(RNN_5b, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.gru = nn.GRU(input_size=input_size, hidden_size=hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.gru.hidden_size).to(x.device)\n",
    "\n",
    "\n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        out = self.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99d3e51",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c99d3e51",
    "outputId": "5d94afaa-8e24-4416-88d8-044141424edb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN_5b(\n",
       "  (gru): GRU(300, 10, batch_first=True)\n",
       "  (fc): Linear(in_features=10, out_features=2, bias=True)\n",
       "  (softmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_task5b = RNN_5b(300,10,2)\n",
    "model_task5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gu_8QHGgxWUG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gu_8QHGgxWUG",
    "outputId": "c3db01d9-0ee2-4db7-ea25-a358a4adc508"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading predefined weights (saved)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the state dict\n",
    "state_dict = torch.load('model_task5b(2).pth', map_location=device)\n",
    "\n",
    "# Load the state dict to the model\n",
    "model_task5b.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e9401f",
   "metadata": {
    "id": "e1e9401f"
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_task5b.parameters(),lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a06c36",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "75a06c36",
    "outputId": "946da270-3cb1-4b8b-c8af-bc8cec5ea7ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0\n",
      "Epoch: 1 \tTraining Loss: 0.427826 \tTest Loss: 0.455237\n",
      "Epoch: 6 \tTraining Loss: 0.427878 \tTest Loss: 0.453585\n",
      "Epoch: 11 \tTraining Loss: 0.427601 \tTest Loss: 0.452934\n",
      "Epoch: 16 \tTraining Loss: 0.427415 \tTest Loss: 0.453379\n",
      "Epoch: 21 \tTraining Loss: 0.427180 \tTest Loss: 0.453180\n",
      "Epoch: 26 \tTraining Loss: 0.427114 \tTest Loss: 0.453084\n",
      "Epoch: 31 \tTraining Loss: 0.426851 \tTest Loss: 0.453103\n",
      "Epoch: 36 \tTraining Loss: 0.426395 \tTest Loss: 0.454192\n",
      "Epoch: 41 \tTraining Loss: 0.426244 \tTest Loss: 0.457943\n",
      "Epoch: 46 \tTraining Loss: 0.426164 \tTest Loss: 0.454048\n",
      "Epoch: 51 \tTraining Loss: 0.426178 \tTest Loss: 0.459215\n",
      "Epoch: 56 \tTraining Loss: 0.425802 \tTest Loss: 0.453513\n",
      "Epoch: 61 \tTraining Loss: 0.425443 \tTest Loss: 0.455512\n",
      "Epoch: 66 \tTraining Loss: 0.425507 \tTest Loss: 0.455220\n",
      "Epoch: 71 \tTraining Loss: 0.425332 \tTest Loss: 0.455201\n",
      "Epoch: 76 \tTraining Loss: 0.425002 \tTest Loss: 0.453309\n",
      "Epoch: 81 \tTraining Loss: 0.424859 \tTest Loss: 0.453884\n",
      "Epoch: 86 \tTraining Loss: 0.424623 \tTest Loss: 0.459841\n",
      "Epoch: 91 \tTraining Loss: 0.424486 \tTest Loss: 0.454053\n",
      "Epoch: 96 \tTraining Loss: 0.424290 \tTest Loss: 0.453517\n",
      "Epoch: 101 \tTraining Loss: 0.424096 \tTest Loss: 0.453776\n",
      "Epoch: 106 \tTraining Loss: 0.423805 \tTest Loss: 0.453453\n",
      "Epoch: 111 \tTraining Loss: 0.423922 \tTest Loss: 0.454752\n",
      "Epoch: 116 \tTraining Loss: 0.423530 \tTest Loss: 0.453878\n",
      "Epoch: 121 \tTraining Loss: 0.423425 \tTest Loss: 0.455472\n",
      "Epoch: 126 \tTraining Loss: 0.423303 \tTest Loss: 0.456338\n",
      "Epoch: 131 \tTraining Loss: 0.422947 \tTest Loss: 0.453549\n",
      "Epoch: 136 \tTraining Loss: 0.422824 \tTest Loss: 0.454112\n",
      "Epoch: 141 \tTraining Loss: 0.422594 \tTest Loss: 0.454062\n",
      "Epoch: 146 \tTraining Loss: 0.422504 \tTest Loss: 0.455184\n",
      "Epoch: 151 \tTraining Loss: 0.422309 \tTest Loss: 0.453673\n",
      "Epoch: 156 \tTraining Loss: 0.421925 \tTest Loss: 0.458717\n",
      "Epoch: 161 \tTraining Loss: 0.421994 \tTest Loss: 0.454776\n",
      "Epoch: 166 \tTraining Loss: 0.421719 \tTest Loss: 0.453877\n",
      "Epoch: 171 \tTraining Loss: 0.421462 \tTest Loss: 0.454111\n",
      "Epoch: 176 \tTraining Loss: 0.421563 \tTest Loss: 0.454158\n",
      "Epoch: 181 \tTraining Loss: 0.421307 \tTest Loss: 0.456691\n",
      "Epoch: 186 \tTraining Loss: 0.420986 \tTest Loss: 0.454429\n",
      "Epoch: 191 \tTraining Loss: 0.420921 \tTest Loss: 0.454812\n",
      "Epoch: 196 \tTraining Loss: 0.420880 \tTest Loss: 0.454241\n"
     ]
    }
   ],
   "source": [
    "#actual training:\n",
    "#1200 so far\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {device}\")\n",
    "\n",
    "# Move the model to the device\n",
    "model_task5b.to(device)\n",
    "\n",
    "epochs = 200\n",
    "for e in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "\n",
    "    model_task5b.train()  # prep model for training\n",
    "\n",
    "    for data, target in train_loader_5:\n",
    "        # Move data and target labels to the device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model_task5b(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "\n",
    "    model_task5b.eval()  # prep model for evaluation\n",
    "\n",
    "    for data, target in test_loader_5:\n",
    "        # Move data and target labels to the device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output = model_task5b(data)\n",
    "        loss = criterion(output, target)\n",
    "        test_loss += loss.item() * data.size(0)\n",
    "\n",
    "    train_loss = train_loss / len(train_loader_5.dataset)\n",
    "    test_loss = test_loss / len(test_loader_5.dataset)\n",
    "\n",
    "    if e % 5 == 0:\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tTest Loss: {:.6f}'.format(\n",
    "            e + 1,\n",
    "            train_loss,\n",
    "            test_loss\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EA5SyXgX8uYh",
   "metadata": {
    "id": "EA5SyXgX8uYh"
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"model1_5b.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(model_task5b, f)\n",
    "torch.save(model_task5b.state_dict(), 'model_task5b.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "m8Y5j_RIqG0M",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m8Y5j_RIqG0M",
    "outputId": "4ed13647-2a9b-4801-e3a9-6f992d349b3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7837\n"
     ]
    }
   ],
   "source": [
    "#calculating accuracy\n",
    "preds = []\n",
    "labels=[]\n",
    "for data,target in test_loader_5:\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    output = model_task5b(data)\n",
    "    preds += list(torch.argmax(output,dim=1).cpu())\n",
    "    labels += list(target.cpu())\n",
    "    # preds.append(torch.argmax(output,dim=1).cpu())\n",
    "    # labels.append(target[0].cpu())\n",
    "print(\"Accuracy: \",accuracy_score(preds,labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a529675c",
   "metadata": {
    "id": "a529675c"
   },
   "outputs": [],
   "source": [
    "class RNN_task5c(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        super(RNN_task5c, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "#         self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         x = self.embedding(x)\n",
    "        h0 = torch.zeros(1, x.size(0), self.lstm.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(1, x.size(0), self.lstm.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        out = self.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82af0365",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82af0365",
    "outputId": "7c029826-cf49-443e-b04a-b7510dc5ee5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN_task5c(\n",
       "  (lstm): LSTM(300, 10, batch_first=True)\n",
       "  (fc): Linear(in_features=10, out_features=2, bias=True)\n",
       "  (softmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_task5c = RNN_task5c(300,10,2)\n",
    "model_task5c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-6GX7gTs8xTQ",
   "metadata": {
    "id": "-6GX7gTs8xTQ"
   },
   "outputs": [],
   "source": [
    "lr = 0.0001 # was 0.001 for the past 1500 epochs\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_task5c.parameters(),lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6vDSnKPuEh-x",
   "metadata": {
    "id": "6vDSnKPuEh-x"
   },
   "outputs": [],
   "source": [
    "count = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "t1NM3lps8xRJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t1NM3lps8xRJ",
    "outputId": "7a6a92e0-ed2a-4f28-e93a-791fa5bdf4e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0\n",
      "Epoch: 1 \tTraining Loss: 0.412370 \tTest Loss: 0.458881\n",
      "Epoch: 6 \tTraining Loss: 0.412301 \tTest Loss: 0.458963\n",
      "Epoch: 11 \tTraining Loss: 0.412250 \tTest Loss: 0.458905\n",
      "Epoch: 16 \tTraining Loss: 0.412281 \tTest Loss: 0.458917\n",
      "Epoch: 21 \tTraining Loss: 0.412252 \tTest Loss: 0.459147\n",
      "Epoch: 26 \tTraining Loss: 0.412236 \tTest Loss: 0.459024\n",
      "Epoch: 31 \tTraining Loss: 0.412165 \tTest Loss: 0.458975\n",
      "Epoch: 36 \tTraining Loss: 0.412203 \tTest Loss: 0.459495\n",
      "Epoch: 41 \tTraining Loss: 0.412188 \tTest Loss: 0.459074\n",
      "Epoch: 46 \tTraining Loss: 0.412148 \tTest Loss: 0.459029\n",
      "Epoch: 51 \tTraining Loss: 0.412112 \tTest Loss: 0.459152\n",
      "Epoch: 56 \tTraining Loss: 0.412150 \tTest Loss: 0.459204\n",
      "Epoch: 61 \tTraining Loss: 0.412101 \tTest Loss: 0.458967\n",
      "Epoch: 66 \tTraining Loss: 0.412097 \tTest Loss: 0.459279\n",
      "Epoch: 71 \tTraining Loss: 0.412042 \tTest Loss: 0.459022\n",
      "Epoch: 76 \tTraining Loss: 0.412061 \tTest Loss: 0.459170\n",
      "Epoch: 81 \tTraining Loss: 0.411979 \tTest Loss: 0.459350\n",
      "Epoch: 86 \tTraining Loss: 0.411970 \tTest Loss: 0.461255\n",
      "Epoch: 91 \tTraining Loss: 0.411951 \tTest Loss: 0.459057\n",
      "Epoch: 96 \tTraining Loss: 0.411928 \tTest Loss: 0.459012\n",
      "Epoch: 101 \tTraining Loss: 0.411932 \tTest Loss: 0.459191\n",
      "Epoch: 106 \tTraining Loss: 0.411865 \tTest Loss: 0.459408\n",
      "Epoch: 111 \tTraining Loss: 0.411903 \tTest Loss: 0.459250\n",
      "Epoch: 116 \tTraining Loss: 0.411945 \tTest Loss: 0.458920\n",
      "Epoch: 121 \tTraining Loss: 0.411865 \tTest Loss: 0.459446\n",
      "Epoch: 126 \tTraining Loss: 0.411861 \tTest Loss: 0.459080\n",
      "Epoch: 131 \tTraining Loss: 0.411835 \tTest Loss: 0.459192\n",
      "Epoch: 136 \tTraining Loss: 0.411822 \tTest Loss: 0.459604\n",
      "Epoch: 141 \tTraining Loss: 0.411808 \tTest Loss: 0.459138\n",
      "Epoch: 146 \tTraining Loss: 0.411779 \tTest Loss: 0.459093\n",
      "Epoch: 151 \tTraining Loss: 0.411753 \tTest Loss: 0.459182\n",
      "Epoch: 156 \tTraining Loss: 0.411764 \tTest Loss: 0.459163\n",
      "Epoch: 161 \tTraining Loss: 0.411638 \tTest Loss: 0.459385\n",
      "Epoch: 166 \tTraining Loss: 0.411729 \tTest Loss: 0.459324\n",
      "Epoch: 171 \tTraining Loss: 0.411734 \tTest Loss: 0.459047\n",
      "Epoch: 176 \tTraining Loss: 0.411703 \tTest Loss: 0.459108\n",
      "Epoch: 181 \tTraining Loss: 0.411625 \tTest Loss: 0.458997\n",
      "Epoch: 186 \tTraining Loss: 0.411594 \tTest Loss: 0.459070\n",
      "Epoch: 191 \tTraining Loss: 0.411612 \tTest Loss: 0.459010\n",
      "Epoch: 196 \tTraining Loss: 0.411611 \tTest Loss: 0.459280\n"
     ]
    }
   ],
   "source": [
    "#1900\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {device}\")\n",
    "\n",
    "# Move the model to the device\n",
    "model_task5c.to(device)\n",
    "\n",
    "epochs = 200\n",
    "for e in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "\n",
    "    model_task5c.train()  # prep model for training\n",
    "\n",
    "    for data, target in train_loader_5:\n",
    "        # Move data and target labels to the device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model_task5c(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "\n",
    "    model_task5c.eval()  # prep model for evaluation\n",
    "\n",
    "    for data, target in test_loader_5:\n",
    "        # Move data and target labels to the device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output = model_task5c(data)\n",
    "        loss = criterion(output, target)\n",
    "        test_loss += loss.item() * data.size(0)\n",
    "\n",
    "    train_loss = train_loss / len(train_loader_5.dataset)\n",
    "    test_loss = test_loss / len(test_loader_5.dataset)\n",
    "\n",
    "    if e % 5 == 0:\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tTest Loss: {:.6f}'.format(\n",
    "            e + 1,\n",
    "            train_loss,\n",
    "            test_loss\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e-oLfQO58xOz",
   "metadata": {
    "id": "e-oLfQO58xOz"
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"model1_5c.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(model_task5c, f)\n",
    "torch.save(model_task5c.state_dict(), f'/content/drive/MyDrive/Shreya Data/Shreya NLP/HW3/trained_models/model_task5c_{count}.pth')\n",
    "count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZQSfdfcD8xLs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZQSfdfcD8xLs",
    "outputId": "82569348-86de-4dfb-853d-a9a104aa6f15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7805\n"
     ]
    }
   ],
   "source": [
    "#calculating accuracy\n",
    "preds = []\n",
    "labels=[]\n",
    "for data,target in test_loader_5:\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    output = model_task5c(data)\n",
    "    preds += list(torch.argmax(output,dim=1).cpu())\n",
    "    labels += list(target.cpu())\n",
    "    # preds.append(torch.argmax(output,dim=1).cpu())\n",
    "    # labels.append(target[0].cpu())\n",
    "print(\"Accuracy: \",accuracy_score(preds,labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672mqgb3ef21",
   "metadata": {
    "id": "672mqgb3ef21"
   },
   "source": [
    "**Conclusion on training models**: \\\n",
    "Of the three models, the GRU performs the best, performing slightly better than the LSTM unit cell. \\\n",
    "All the models were trained beyond overfitting till the point where the test loss started increasing with every epoch, following prof. Rostami's advice about deep learning models generalize better despite being overfitted on the training data \\\n",
    "Of the three, a Simple RNN got the least accuracy of 75.2, followed by the LSTM unit cell, which got an accuracy of 78.1, and then the GRU with 78.4% accuracy on the test set."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "e29bd63a",
    "5fe0a8c9"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
